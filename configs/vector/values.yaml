# The Vector Kubernetes integration automatically defines a
# kubernetes_logs source that is made available to you.
# You do not need to define a log source.

# Extra env vars to pass to the `vector` container.
env: []

# Global parts of the generated `vector` config.
globalOptions:
  # Specifies the (in-container) data dir used by `vector`.
  dataDir: "/vector-data-dir"

# Schema part of the generated `vector` config.
logSchema:
  hostKey: "host"
  messageKey: "message"
  sourceTypeKey: "source_type"
  timestampKey: "timestamp"

vectorApi:
  enabled: true

# The "built-in" kubernetes logs source. Will be added by default, unless
# explicitly disabled.
kubernetesLogsSource:
  # Disable to omit the kubernetes logs source from being added.
  enabled: true
  # The name to use for the "built-in" kubernetes logs source.
  sourceId: kubernetes_logs
  # Raw TOML config to embed at the kubernetes logs source.
  # rawConfig: |
  #   annotation_fields.flat_labels = true

# Sources to add to the generated `vector` config (besides "built-in" kubernetes
# logs source).
sources:
  {}
  # source_name:
  #   type: "source_type"
  #   rawConfig: |
  #     option = "value"

# Transforms to add to the generated `vector` config.
transforms: {}
#   # https://github.com/timberio/vector/issues/3057
#   remove_timestamps:
#     type: "remove_fields"
#     inputs: ["kubernetes_logs"]
#     rawConfig: |
#       fields = ["timestamp"]

# Sinks to add to the generated `vector` config.
sinks:
  loki:
    # https://vector.dev/docs/reference/sinks/loki/
    type: loki
    inputs: ["kubernetes_logs"]
    rawConfig: |
      endpoint = "http://loki.monitoring:3100"
      remove_timestamp = true
      encoding.codec = 'json'
      labels.forwarder = 'vector'
      labels.file = '{{ file }}'
      labels.stream = '{{ stream }}'
      labels.source_type = '{{ source_type }}'
      labels.namespace = '{{ kubernetes.pod_namespace }}'
      labels.pod_name = '{{ kubernetes.pod_name }}'
      labels.pod_uid = '{{ kubernetes.pod_uid }}'
      labels.pod_ip = '{{ kubernetes.pod_ip }}'
      labels.pod_ips = '{{ kubernetes.pod_ips }}'
      labels.pod_node_name = '{{ kubernetes.pod_node_name }}'
      labels.app = '{{ kubernetes.pod_labels.app }}'
      labels.kubernetes_io_instance = '{{ kubernetes.pod_labels.app\.kubernetes\.io/instance }}'
      labels.kubernetes_io_component = '{{ kubernetes.pod_labels.app\.kubernetes\.io/component }}'
      labels.kubernetes_io_name = '{{ kubernetes.pod_labels.app\.kubernetes\.io/name }}'
      labels.source_type = '{{ source_type }}'
      labels.container_name = '{{ kubernetes.container_name }}'
      labels.container_image = '{{ kubernetes.container_image }}'
      request.in_flight_limit = 1
  kafka0:
    type: kafka
    inputs: ["kubernetes_logs"]
    rawConfig: |
      # General
      bootstrap_servers = "kafka0-headless.kafka:9092"
      compression = "gzip" # optional, default
      key_field = "pod" # required
      topic = "kube-logs" # required
      encoding.codec = "json"
